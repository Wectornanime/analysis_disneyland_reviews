{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0106e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa as libs\n",
    "from utils.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f44d33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Wectornanime\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Wectornanime\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Wectornanime\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Wectornanime\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baixar recursos NLTK\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9670155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuração\n",
    "\n",
    "dataset_uri = './database/DisneylandReviews.csv'\n",
    "dataset_encoding = 'latin1'\n",
    "\n",
    "# 'bert-base-uncased' bom para inglês\n",
    "# 'distilbert-base-uncased' mais leve e mais rápido\n",
    "pre_trined_model_name = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b2fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa o dataset\n",
    "df = pd.read_csv(dataset_uri, encoding=dataset_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f54993",
   "metadata": {},
   "source": [
    "## Análise e Tratamento de Dados (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ead7625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670772142</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670682799</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670623270</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670607911</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>670607296</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
       "0  670772142       4     2019-4             Australia   \n",
       "1  670682799       4     2019-5           Philippines   \n",
       "2  670623270       4     2019-4  United Arab Emirates   \n",
       "3  670607911       4     2019-4             Australia   \n",
       "4  670607296       4     2019-4        United Kingdom   \n",
       "\n",
       "                                         Review_Text               Branch  \n",
       "0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong  \n",
       "1  Its been a while since d last time we visit HK...  Disneyland_HongKong  \n",
       "2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong  \n",
       "3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong  \n",
       "4  the location is not in the city, took around 1...  Disneyland_HongKong  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# primeiras linhas do dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de60bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42656 entries, 0 to 42655\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Review_ID          42656 non-null  int64 \n",
      " 1   Rating             42656 non-null  int64 \n",
      " 2   Year_Month         42656 non-null  object\n",
      " 3   Reviewer_Location  42656 non-null  object\n",
      " 4   Review_Text        42656 non-null  object\n",
      " 5   Branch             42656 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# informações da base\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b216ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review_ID            0\n",
       "Rating               0\n",
       "Year_Month           0\n",
       "Reviewer_Location    0\n",
       "Review_Text          0\n",
       "Branch               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificação de valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94cd37d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5    23146\n",
       "4    10775\n",
       "3     5109\n",
       "2     2127\n",
       "1     1499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a6f0a",
   "metadata": {},
   "source": [
    "## Preparar o Rótulo (Sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44642d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670772142</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670682799</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670623270</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670607911</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>670607296</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
       "0  670772142       4     2019-4             Australia   \n",
       "1  670682799       4     2019-5           Philippines   \n",
       "2  670623270       4     2019-4  United Arab Emirates   \n",
       "3  670607911       4     2019-4             Australia   \n",
       "4  670607296       4     2019-4        United Kingdom   \n",
       "\n",
       "                                         Review_Text               Branch  \\\n",
       "0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong   \n",
       "1  Its been a while since d last time we visit HK...  Disneyland_HongKong   \n",
       "2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong   \n",
       "3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong   \n",
       "4  the location is not in the city, took around 1...  Disneyland_HongKong   \n",
       "\n",
       "  Sentiment  \n",
       "0  Positivo  \n",
       "1  Positivo  \n",
       "2  Positivo  \n",
       "3  Positivo  \n",
       "4  Positivo  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cria uma coluna chamada 'Sentiment'\n",
    "df['Sentiment'] = df['Rating'].apply(get_sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219f7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove os sentimentos neutros\n",
    "# para facilitar o classificador\n",
    "df_final = df[df['Sentiment'] != 'Neutro'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a1ce1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text Sentiment\n",
       "0  If you've ever been to Disneyland anywhere you...  Positivo\n",
       "1  Its been a while since d last time we visit HK...  Positivo\n",
       "2  Thanks God it wasn   t too hot or too humid wh...  Positivo\n",
       "3  HK Disneyland is a great compact park. Unfortu...  Positivo\n",
       "4  the location is not in the city, took around 1...  Positivo"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separa as colunas que queremos trabalhar\n",
    "df_final = df_final[['Review_Text', 'Sentiment']]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4172552",
   "metadata": {},
   "source": [
    "## Pré-processamento de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5092e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o lematizador e stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a8cfd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa a função responsável por fazer o pré-processamento de texto\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Converte para minúsculas\n",
    "    text = text.lower()\n",
    "    # Remove tudo que não for letra\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokeniza\n",
    "    tokens = text.split()\n",
    "    # tokens = word_tokenize(text) # o recurso punkt esta dando erro\n",
    "    # Remove stopwords e lemmatiza\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb074061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Processed_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>youve ever disneyland anywhere youll find disn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>since last time visit hk disneyland yet time s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>thanks god hot humid visiting park otherwise w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>hk disneyland great compact park unfortunately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>location city took around hour kowlon kid like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  \\\n",
       "0  If you've ever been to Disneyland anywhere you...   \n",
       "1  Its been a while since d last time we visit HK...   \n",
       "2  Thanks God it wasn   t too hot or too humid wh...   \n",
       "3  HK Disneyland is a great compact park. Unfortu...   \n",
       "4  the location is not in the city, took around 1...   \n",
       "\n",
       "                                    Processed_Review  \n",
       "0  youve ever disneyland anywhere youll find disn...  \n",
       "1  since last time visit hk disneyland yet time s...  \n",
       "2  thanks god hot humid visiting park otherwise w...  \n",
       "3  hk disneyland great compact park unfortunately...  \n",
       "4  location city took around hour kowlon kid like...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o pré-processamento na coluna 'Review_Text'\n",
    "df_final['Processed_Review'] = df_final['Review_Text'].apply(preprocess_text)\n",
    "\n",
    "df_final[['Review_Text', 'Processed_Review']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c4c11",
   "metadata": {},
   "source": [
    "## Extração de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de269ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em treino e teste\n",
    "X = df_final['Processed_Review']\n",
    "y = df_final['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a1c900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train_tfidf: (30037, 5000)\n",
      "Shape X_test_tfidf: (7510, 5000)\n"
     ]
    }
   ],
   "source": [
    "# usando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Shape X_train_tfidf:\", X_train_tfidf.shape)\n",
    "print(\"Shape X_test_tfidf:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd43c6",
   "metadata": {},
   "source": [
    "## Modelagem e Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8167b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas com as métricas\n",
    "\n",
    "accuracy = {}\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1 = {}\n",
    "confusion = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7dc14a",
   "metadata": {},
   "source": [
    "### Modelos Supervisionados Tradicionais (com TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29e0e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "mlp_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_mlp = mlp_model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy['mlp'] = accuracy_score(y_test, y_pred_mlp)\n",
    "precision['mlp'] = precision_score(y_test, y_pred_mlp, average='weighted')\n",
    "recall['mlp'] = recall_score(y_test, y_pred_mlp, average='weighted')\n",
    "f1['mlp'] = f1_score(y_test, y_pred_mlp, average='weighted')\n",
    "confusion['mlp'] = confusion_matrix(y_test, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7a470c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy['svm'] = accuracy_score(y_test, y_pred_svm)\n",
    "precision['svm'] = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "recall['svm'] = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "f1['svm'] = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "confusion['svm'] = confusion_matrix(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb29100",
   "metadata": {},
   "source": [
    "### Modelo Pré-treinado (BERT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1865f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wectornanime\\Workspace\\GitHub\\analysis_disneyland_reviews\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Wectornanime\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Mapear rótulos para IDs (BERT espera IDs numéricos)\n",
    "label_map = {'Negativo': 0, 'Positivo': 1}\n",
    "id_map = {0: 'Negativo', 1: 'Positivo'}\n",
    "df_final['labels'] = df_final['Sentiment'].map(label_map)\n",
    "\n",
    "# Carregar Tokenizer e Modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(pre_trined_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pre_trined_model_name, num_labels=len(label_map))\n",
    "\n",
    "# Preparar um dataset no formato da biblioteca `datasets`\n",
    "# `datasets` é uma biblioteca otimizada para trabalhar com grandes volumes de texto para modelos Transformer\n",
    "data_dict = {\n",
    "    'text': df_final['Review_Text'].tolist(),\n",
    "    'labels': df_final['labels'].tolist()\n",
    "}\n",
    "full_dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b514f3f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Stratifying by column is only supported for ClassLabel column, and column labels is Value.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dividir o dataset em treino e teste (usando o split do datasets para BERT)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_test_split = \u001b[43mfull_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify_by_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m train_dataset = train_test_split[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m test_dataset = train_test_split[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wectornanime\\Workspace\\GitHub\\analysis_disneyland_reviews\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wectornanime\\Workspace\\GitHub\\analysis_disneyland_reviews\\.venv\\Lib\\site-packages\\datasets\\fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wectornanime\\Workspace\\GitHub\\analysis_disneyland_reviews\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:4696\u001b[39m, in \u001b[36mDataset.train_test_split\u001b[39m\u001b[34m(self, test_size, train_size, shuffle, stratify_by_column, seed, generator, keep_in_memory, load_from_cache_file, train_indices_cache_file_name, test_indices_cache_file_name, writer_batch_size, train_new_fingerprint, test_new_fingerprint)\u001b[39m\n\u001b[32m   4694\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstratify_by_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._info.features.keys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   4695\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._info.features[stratify_by_column], ClassLabel):\n\u001b[32m-> \u001b[39m\u001b[32m4696\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4697\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStratifying by column is only supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mClassLabel.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m column, and column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstratify_by_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m._info.features[stratify_by_column]).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4698\u001b[39m     )\n\u001b[32m   4699\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4700\u001b[39m     train_indices, test_indices = \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   4701\u001b[39m         stratified_shuffle_split_generate_indices(\n\u001b[32m   4702\u001b[39m             \u001b[38;5;28mself\u001b[39m.with_format(\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m)[stratify_by_column], n_train, n_test, rng=generator\n\u001b[32m   4703\u001b[39m         )\n\u001b[32m   4704\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Stratifying by column is only supported for ClassLabel column, and column labels is Value."
     ]
    }
   ],
   "source": [
    "# Dividir o dataset em treino e teste (usando o split do datasets para BERT)\n",
    "train_test_split = full_dataset.train_test_split(test_size=0.2, stratify_by_column=\"labels\", seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
