{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d72b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wectornanimefelipe\\workspace\\wectornanime\\analysis_disneyland_reviews\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# instala dependências extras\n",
    "\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0106e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa as libs\n",
    "from utils.utils import *\n",
    "from utils.bert_review_dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f44d33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wectornanimefelipe\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wectornanimefelipe\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wectornanimefelipe\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\wectornanimefelipe\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baixar recursos NLTK\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9670155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuração\n",
    "\n",
    "dataset_uri = './database/DisneylandReviews.csv'\n",
    "dataset_encoding = 'latin1'\n",
    "\n",
    "# 'bert-base-uncased' bom para inglês\n",
    "# 'distilbert-base-uncased' mais leve e mais rápido\n",
    "#  'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "pre_trined_model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "pre_trined_model = 'MarieAngeA13/Sentiment-Analysis-BERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b2fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa o dataset\n",
    "df = pd.read_csv(dataset_uri, encoding=dataset_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f54993",
   "metadata": {},
   "source": [
    "## Análise e Tratamento de Dados (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primeiras linhas do dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de60bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# informações da base\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b216ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificação de valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94cd37d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5    23146\n",
       "4    10775\n",
       "3     5109\n",
       "2     2127\n",
       "1     1499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a6f0a",
   "metadata": {},
   "source": [
    "## Preparar o Rótulo (Sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44642d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670772142</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670682799</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670623270</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670607911</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>670607296</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
       "0  670772142       4     2019-4             Australia   \n",
       "1  670682799       4     2019-5           Philippines   \n",
       "2  670623270       4     2019-4  United Arab Emirates   \n",
       "3  670607911       4     2019-4             Australia   \n",
       "4  670607296       4     2019-4        United Kingdom   \n",
       "\n",
       "                                         Review_Text               Branch  \\\n",
       "0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong   \n",
       "1  Its been a while since d last time we visit HK...  Disneyland_HongKong   \n",
       "2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong   \n",
       "3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong   \n",
       "4  the location is not in the city, took around 1...  Disneyland_HongKong   \n",
       "\n",
       "  Sentiment  \n",
       "0  Positivo  \n",
       "1  Positivo  \n",
       "2  Positivo  \n",
       "3  Positivo  \n",
       "4  Positivo  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cria uma coluna chamada 'Sentiment'\n",
    "df['Sentiment'] = df['Rating'].apply(get_sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "219f7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove os sentimentos neutros\n",
    "# para facilitar o classificador\n",
    "df_final = df[df['Sentiment'] != 'Neutro'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a1ce1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text Sentiment\n",
       "0  If you've ever been to Disneyland anywhere you...  Positivo\n",
       "1  Its been a while since d last time we visit HK...  Positivo\n",
       "2  Thanks God it wasn   t too hot or too humid wh...  Positivo\n",
       "3  HK Disneyland is a great compact park. Unfortu...  Positivo\n",
       "4  the location is not in the city, took around 1...  Positivo"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separa as colunas que queremos trabalhar\n",
    "df_final = df_final[['Review_Text', 'Sentiment']]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4172552",
   "metadata": {},
   "source": [
    "## Pré-processamento de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5092e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o lematizador e stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a8cfd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa a função responsável por fazer o pré-processamento de texto\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Converte para minúsculas\n",
    "    text = text.lower()\n",
    "    # Remove tudo que não for letra\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokeniza\n",
    "    tokens = text.split()\n",
    "    # tokens = word_tokenize(text) # o recurso punkt esta dando erro\n",
    "    # Remove stopwords e lemmatiza\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb074061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wectornanimefelipe\\AppData\\Local\\Temp\\ipykernel_1256\\1431139256.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['Processed_Review'] = df_final['Review_Text'].apply(preprocess_text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Processed_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>youve ever disneyland anywhere youll find disn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>since last time visit hk disneyland yet time s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>thanks god hot humid visiting park otherwise w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>hk disneyland great compact park unfortunately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>location city took around hour kowlon kid like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  \\\n",
       "0  If you've ever been to Disneyland anywhere you...   \n",
       "1  Its been a while since d last time we visit HK...   \n",
       "2  Thanks God it wasn   t too hot or too humid wh...   \n",
       "3  HK Disneyland is a great compact park. Unfortu...   \n",
       "4  the location is not in the city, took around 1...   \n",
       "\n",
       "                                    Processed_Review  \n",
       "0  youve ever disneyland anywhere youll find disn...  \n",
       "1  since last time visit hk disneyland yet time s...  \n",
       "2  thanks god hot humid visiting park otherwise w...  \n",
       "3  hk disneyland great compact park unfortunately...  \n",
       "4  location city took around hour kowlon kid like...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o pré-processamento na coluna 'Review_Text'\n",
    "df_final['Processed_Review'] = df_final['Review_Text'].apply(preprocess_text)\n",
    "\n",
    "df_final[['Review_Text', 'Processed_Review']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c4c11",
   "metadata": {},
   "source": [
    "## Extração de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993fac15",
   "metadata": {},
   "source": [
    "### Modelos Supervisionados Tradicionais (com TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de269ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em treino e teste\n",
    "X = df_final['Processed_Review']\n",
    "y = df_final['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Shape X_train_tfidf:\", X_train_tfidf.shape)\n",
    "print(\"Shape X_test_tfidf:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8cf89",
   "metadata": {},
   "source": [
    "### Modelo Pré-treinado (BERT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "338e7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear rótulos para IDs (BERT espera IDs numéricos)\n",
    "label_map = {'Negativo': 0, 'Positivo': 1}\n",
    "\n",
    "# Dividir treino e teste\n",
    "texts = df_final['Processed_Review'].tolist()\n",
    "labels = df_final['Sentiment'].map(label_map).tolist()\n",
    "\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e8ce837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Carregar Tokenizer e Modelo\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pre_trined_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pre_trined_model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b639e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização\n",
    "\n",
    "train_encodings = tokenizer(X_train_bert, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(X_test_bert, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd43c6",
   "metadata": {},
   "source": [
    "## Modelagem e Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas com as métricas\n",
    "\n",
    "accuracy = {}\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1 = {}\n",
    "confusion = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7dc14a",
   "metadata": {},
   "source": [
    "### Modelos Supervisionados Tradicionais (com TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100), max_iter=500, random_state=42)\n",
    "mlp_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_mlp = mlp_model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy['mlp'] = accuracy_score(y_test, y_pred_mlp)\n",
    "precision['mlp'] = precision_score(y_test, y_pred_mlp, average='weighted')\n",
    "recall['mlp'] = recall_score(y_test, y_pred_mlp, average='weighted')\n",
    "f1['mlp'] = f1_score(y_test, y_pred_mlp, average='weighted')\n",
    "confusion['mlp'] = confusion_matrix(y_test, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a470c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy['svm'] = accuracy_score(y_test, y_pred_svm)\n",
    "precision['svm'] = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "recall['svm'] = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "f1['svm'] = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "confusion['svm'] = confusion_matrix(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb29100",
   "metadata": {},
   "source": [
    "### Modelo Pré-treinado (BERT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "724a2a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(model=pre_trined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4fc992c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.8375326991081238}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(\"Its Disneyland! But don't have happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d447a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
